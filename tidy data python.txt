#glob
def :can open multiple files by using regex matching to get the filenames

ex: import glob

student_files = glob.glob('exam*.csv')

df_list = []
for files in student_files:
  data = pd.read_csv(files)
  df_list.append(data)

students = pd.concat(df_list)

---

# pd.melt()

def : change the columns of df the way we want

df = pd.melt(frame=df, id_vars="Account", value_vars=["Checking","Savings"], value_name="Amount", var_name="Account Type")

df.columns(["Account", "Account Type", "Amount"])		==> to rename column

---

# .duplicated()

duplicates = students.duplicated()
print(duplicates.value_counts())		==> true values are duplicated
students = students.drop_duplicates()

---

#Splitting by Index

- the following code get gender_age column and split it to 2 columns

students['gender'] = students.gender_age.str[0]
students['age'] = students.gender_age.str[1:]


#Splitting by Character

- The following code split full_name column to 2 diffrent column

name_split = students['full_name'].str.split(" ")
students['first_name'] = name_split.str.get(0)
students['last_name'] = name_split.str.get(1)

---

#String Parsing - string to number

## .to_numeric() 

- This code takes all score column values and replace % with nothing them turn them to numeric

students.score = students['score'].replace(['%'], '', regex=True)
students.score = pd.to_numeric(students.score)



# int in middle

-Following code get the number of str and turn column to int
!grade like 11th grade

tudents_grade = students.grade.str.split('(\d+)', expand=True)
students.grade = pd.to_numeric(students_grade[1])

---

#Missing Values

## .dropna()
bill_df = bill_df.dropna()
bill_df = bill_df.dropna(subset=['num_guests'])


## .fillna()
df = df.fillna(value={"column":df.column.mean(), "num_guests":0})


---

#deletation

##Listwise Deletion
data.dropna(inplace=True)

##Pairwise Deletion
data.dropna(subset=['Height','Education'], 	#only looks at these two columns
            inplace=True, 			#removes the rows and keeps the data variable
            how='any') 				#removes data with missing data in either field


---

#Fill for time-series data (single imputation)

## LOCF stands for Last Observation Carried Forward
df['comfort'].ffill(axis=0, inplace=True)			==> (for pandas df) Applying Forward Fill (another name for LOCF) on the comfort column

impyute.imputation.ts.locf(data, axis=0)			==> (for NumPy array) Applying LOCF to the dataset


## NOCB stands for Next Observation Carried Backward
df['comfort'].bfill(axis=0, inplace=True)			==> for pandas datasets

impyute.imputation.ts.nocb(data, axis=0)


## BOCF, or Baseline Observation Carried Forward
baseline = df['concentration'][0]				==> Isolate the first (baseline) value for our data

df['concentration'].fillna(value=baseline, inplace=True)	==> Replace missing values with our baseline value


## WOCF, or Worst Observation Carried Forward
worst = df['pain'].max()					==> Isolate worst pain value (in this case, the highest)

df['pain'].fillna(value=worst, inplace=True)			==> Replace all missing values with the worst value


---


#Multiple Imputation

example:

```

import numpy as np
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
import pandas as pd

# Create the dataset as a Python dictionary
d = {
    'X': [5.4,13.8,14.7,17.6,np.nan,1.1,12.9,3.4,np.nan,10.2],
    'Y': [18,27.4,np.nan,18.3,49.6,48.9,np.nan,13.6,16.1,42.7],
    'Z': [7.6,4.6,4.2,np.nan,4.7,8.5,3.5,np.nan,1.8,4.7]
}

dTest = {
    'X': [13.1, 10.8, np.nan, 9.7, 11.2],
    'Y': [18.3, np.nan, 14.1, 19.8, 17.5],
    'Z': [4.2, 3.1, 5.7,np.nan, 9.6]
}

# Create the pandas DataFrame from our dictionary
df = pd.DataFrame(data=d)
dfTest = pd.DataFrame(data=dTest)

# Create the IterativeImputer model to predict missing values
imp = IterativeImputer(max_iter=10, random_state=0)

# Fit the model to the test dataset
imp.fit(dfTest)

# Transform the model on the entire dataset
dfComplete = pd.DataFrame(np.round(imp.transform(df),1), columns=['X','Y','Z'])

print(dfComplete.head(10))


```


